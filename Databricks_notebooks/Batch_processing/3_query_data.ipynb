{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most popular category in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "# Create temp view for SQL query\n",
    "df_128a59195de3_pin.createOrReplaceTempView(\"pin\")\n",
    "df_128a59195de3_geo.createOrReplaceTempView(\"geo\")\n",
    "df_128a59195de3_user.createOrReplaceTempView(\"user\")\n",
    "# SQL query\n",
    "result = spark.sql(\n",
    "    \"\"\"SELECT country, category, category_count\n",
    "        FROM (\n",
    "                SELECT country\n",
    "                        ,category\n",
    "                        ,COUNT(*) AS category_count\n",
    "                        ,ROW_NUMBER() OVER (PARTITION BY country ORDER BY COUNT(*) DESC) AS rank\n",
    "                FROM geo \n",
    "                INNER JOIN pin\n",
    "                ON pin.ind = geo.ind\n",
    "                GROUP BY country, category\n",
    "            ) \n",
    "        WHERE rank = 1\"\"\")\n",
    "display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using Pyspark\n",
    "# Create partition by country and order by category_count descending\n",
    "country_categorycount_rank = Window.partitionBy(\"country\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "# Find the most popular category in each country\n",
    "pin_geo.groupBy(\"country\", \"category\").agg(count(\"category\").alias(\"category_count\")) \\\n",
    ".withColumn(\"rank\", row_number().over(country_categorycount_rank)) \\\n",
    ".filter(col(\"rank\") == 1) \\\n",
    ".drop(\"rank\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most popular category for each year between 2018 and 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "result = spark.sql(\n",
    "    \"\"\"SELECT post_year, category, category_count\n",
    "        FROM (\n",
    "                SELECT year(timestamp) as post_year\n",
    "                        ,category\n",
    "                        ,COUNT(*) AS category_count\n",
    "                        ,ROW_NUMBER() OVER (PARTITION BY year(timestamp) ORDER BY COUNT(*) DESC) AS rank\n",
    "                FROM geo \n",
    "                INNER JOIN pin \n",
    "                ON pin.ind = geo.ind\n",
    "                GROUP BY year(timestamp), category\n",
    "            ) \n",
    "        WHERE rank = 1 AND post_year BETWEEN 2018 AND 2022\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using Pyspark\n",
    "# Create partition by year and order by category_count descending\n",
    "year_categorycount_rank = Window.partitionBy(\"post_year\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "# Retrive most popular category between 2018 and 2022\n",
    "# apply filter to post_year between 2018 and 2022\n",
    "pin_geo.withColumn(\"post_year\", year(\"timestamp\")).filter(col(\"post_year\") >= 2018).filter(col(\"post_year\") <= 2022) \n",
    "# group data by country and post_year and aggregate on category count\n",
    ".groupBy(\"post_year\", \"category\").agg(count(\"category\").alias(\"category_count\")) \\\n",
    "# use window function to filter by highest ranking category by year\n",
    ".withColumn(\"rank\", row_number().over(year_categorycount_rank)) \\\n",
    ".filter(col(\"rank\") == 1) \\\n",
    ".drop(\"rank\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User with most followers by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "# Find user with most followers by country\n",
    "result1 = spark.sql(\n",
    "    \"\"\" SELECT country\n",
    "                ,poster_name\n",
    "                ,max_follower_count\n",
    "        FROM (\n",
    "                SELECT country\n",
    "                        ,poster_name\n",
    "                        ,MAX(follower_count) as max_follower_count\n",
    "                        ,ROW_NUMBER() OVER (PARTITION BY country ORDER BY MAX(follower_count) DESC) AS rank\n",
    "                FROM pin \n",
    "                INNER JOIN geo ON geo.ind = pin.ind\n",
    "                GROUP BY country, poster_name\n",
    "        )\n",
    "        WHERE rank = 1\n",
    "        ORDER BY max_follower_count DESC\n",
    "    \"\"\")\n",
    "\n",
    "display(result1)\n",
    "\n",
    "# Identify country with most followers\n",
    "result2 = spark.sql(\n",
    "    \"\"\" SELECT country\n",
    "                ,max_follower_count AS follower_count\n",
    "        FROM (\n",
    "                SELECT country\n",
    "                        ,poster_name\n",
    "                        ,MAX(follower_count) as max_follower_count\n",
    "                        ,ROW_NUMBER() OVER (PARTITION BY country ORDER BY MAX(follower_count) DESC) AS rank\n",
    "                FROM pin \n",
    "                INNER JOIN geo ON geo.ind = pin.ind\n",
    "                GROUP BY country, poster_name\n",
    "        )\n",
    "        WHERE rank = 1\n",
    "        ORDER BY max_follower_count DESC\n",
    "        LIMIT 1\n",
    "    \"\"\")\n",
    "display(result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using Pyspark\n",
    "\n",
    "# Create partition by country and order by follower_count descending\n",
    "country_rank_maxfollowers = Window.partitionBy(\"country\").orderBy(col(\"follower_count\").desc())\n",
    "\n",
    "# Find the user with the most followers in each country\n",
    "max_followers_by_country = pin_geo.withColumn(\"rank\", row_number().over(country_rank_maxfollowers)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"country\", \"poster_name\", \"follower_count\")\n",
    "\n",
    "# get highest number of followers from all countries\n",
    "max_followers_all_countries = max_followers_by_country.select(max(\"follower_count\")).collect()[0][0]\n",
    "\n",
    "# find the country with the user with most followers\n",
    "country_with_max_followers = max_followers_by_country.select(\"*\").where(col(\"follower_count\") == max_followers_all_countries)\n",
    "\n",
    "max_followers_by_country.show()\n",
    "country_with_max_followers.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular category for different age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT age_group, category, category_count\n",
    "    FROM (\n",
    "            SELECT age_group\n",
    "                    ,category\n",
    "                    ,category_count\n",
    "                    ,ROW_NUMBER() OVER (PARTITION BY age_group ORDER BY category_count DESC) AS rank\n",
    "            FROM (\n",
    "                    SELECT\n",
    "                        CASE \n",
    "                            WHEN age BETWEEN 18 AND 24 THEN \"18-24\"\n",
    "                            WHEN age BETWEEN 25 AND 35 THEN \"25-35\"\n",
    "                            WHEN age BETWEEN 36 AND 50 THEN \"36-50\"\n",
    "                            WHEN age > 50 THEN \"+50\"\n",
    "                            ELSE \"Below 18\" \n",
    "                        END AS age_group\n",
    "                        ,category\n",
    "                        ,COUNT(*) AS category_count\n",
    "            FROM user\n",
    "            JOIN pin ON pin.ind = user.ind\n",
    "            GROUP BY age_group, category\n",
    "        )\n",
    "    )\n",
    "    WHERE rank = 1\n",
    "\"\"\")\n",
    "\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define age groups\n",
    "df_user_age = df_128a59195de3_user.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"age\").between(18, 24), \"18-24\")\n",
    "    .when(col(\"age\").between(25, 35), \"25-35\")\n",
    "    .when(col(\"age\").between(36, 50), \"36-50\")\n",
    "    .otherwise(\"+50\")\n",
    ")\n",
    "# Join on 'ind' column\n",
    "df_user_pin = df_user_age.alias(\"user\").join(df_128a59195de3_pin.alias(\"pin\"), col(\"user.ind\") == col(\"pin.ind\"), 'inner')\n",
    "\n",
    "# Create partition by age_group and order by category_count descending\n",
    "age_rank_categorycount = Window.partitionBy(\"age_group\").orderBy(col(\"category_count\").desc())\n",
    "\n",
    "# Find the most popular category for different age groups\n",
    "df_user_pin.groupBy(\"age_group\", \"category\").agg(count(\"category\").alias(\"category_count\")) \\\n",
    ".withColumn(\"rank\", row_number().over(windowAgeGroup)) \\\n",
    ".filter(col(\"rank\") == 1) \\\n",
    ".drop(\"rank\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median follower count for set age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = spark.sql(\"\"\"\n",
    "                    SELECT CASE \n",
    "                                WHEN age BETWEEN 18 AND 24 THEN \"18-24\"\n",
    "                                WHEN age BETWEEN 25 AND 35 THEN \"25-35\"\n",
    "                            WHEN age BETWEEN 36 AND 50 THEN \"36-50\"\n",
    "                            WHEN age > 50 THEN \"+50\"\n",
    "                            ELSE \"NONE\" \n",
    "                        END AS age_group, PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY follower_count) AS median_follower_count\n",
    "                    FROM user \n",
    "                    INNER JOIN pin on pin.ind = user.ind\n",
    "                    GROUP BY age_group\n",
    "                    \"\"\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Pyspark\n",
    "df_user_pin.groupBy(\"age_group\").agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")) \\\n",
    ".orderBy(\"age_group\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users joined each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "\n",
    "results = spark.sql(\"\"\"\n",
    "                    SELECT year(date_joined) as post_year\n",
    "                            ,COUNT(date_joined) as numbers_users_joined\n",
    "                    FROM user \n",
    "                    GROUP by post_year\n",
    "                    HAVING post_year BETWEEN 2015 and 2020\n",
    "                    \"\"\")\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using Pyspark\n",
    "df_128a59195de3_user.withColumn(\"post_year\", year(\"date_joined\")) \\\n",
    ".groupBy(\"post_year\") \\\n",
    ".agg(count(\"user_name\").alias(\"number_users_joined\")) \\\n",
    ".orderBy(\"post_year\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median follower count of users based on joining year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "\n",
    "results = spark.sql(\"\"\"\n",
    "                    SELECT year(date_joined) as join_year\n",
    "                    ,PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY follower_count) AS median_follower_count\n",
    "                    FROM user \n",
    "                    INNER JOIN pin on pin.ind = user.ind\n",
    "                    GROUP by join_year\n",
    "                    HAVING join_year BETWEEN 2015 and 2020\n",
    "                    \"\"\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using Pyspark\n",
    "df_user_pin.withColumn(\"join_year\", year(\"date_joined\")).filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020)) \\\n",
    ".groupBy(\"join_year\") \\\n",
    ".agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")) \\\n",
    ".orderBy(\"join_year\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Median follower count based on age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "\n",
    "results = spark.sql(\"\"\"\n",
    "                    SELECT CASE \n",
    "                                WHEN age BETWEEN 18 AND 24 THEN \"18-24\"\n",
    "                                WHEN age BETWEEN 25 AND 35 THEN \"25-35\"\n",
    "                                WHEN age BETWEEN 36 AND 50 THEN \"36-50\"\n",
    "                                WHEN age > 50 THEN \"+50\"\n",
    "                            ELSE \"Under 18\" \n",
    "                        END AS age_group\n",
    "                        ,year(date_joined) as join_year\n",
    "                        ,PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY follower_count) AS median_follower_count\n",
    "                    FROM user \n",
    "                    INNER JOIN pin on pin.ind = user.ind\n",
    "                    GROUP by join_year, age_group\n",
    "                    HAVING join_year BETWEEN 2015 and 2020\n",
    "                    ORDER BY join_year, age_group\n",
    "                    \"\"\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using Pyspark\n",
    "df_user_pin.withColumn(\"join_year\", year(\"date_joined\")).filter((col(\"join_year\") >= 2015) & (col(\"join_year\") <= 2020)) \\\n",
    ".groupBy(\"join_year\", \"age_group\").agg(percentile_approx(\"follower_count\", 0.5).alias(\"median_follower_count\")) \\\n",
    ".orderBy(\"join_year\", \"age_group\") \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Unmount the bucket from the filestore\n",
    "dbutils.fs.unmount(\"/mnt/user-128a59195de3-bucket\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
